{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3710jvsc74a57bd0563d867f513b1db22a50c0772d3498166496ad16228d7c1d495fd4c7e7a93ad6",
      "display_name": "Python 3.7.10 64-bit ('graph': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "name": "20_modeling_pytoch.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekaratnida/Applied-machine-learning/blob/master/sna/fraud/final/20_modeling_for_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4714VKOKo8cK"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "This notebook will guide you through the process of loading heterogeneous graphs and training models. The heterogeneous graph is based on Deep Graph Library (DGL) implementation, and the training process is based on PyTorch implementation.\n",
        "\n",
        "The CPU is recommended for training when the equipment allows it. If you need to use GPU, please install GPU-based DGL separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsBPiu9io8cR"
      },
      "source": [
        "## Colab setting\n",
        "\n",
        "If you want to train in Colab, please run both cells first and mount to the corresponding path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AICBHAJHa56",
        "outputId": "6c3ccb56-48e2-4f1f-e09b-5f478080d721"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtJfGQ6GHh88",
        "outputId": "cef56d2e-c38d-40f3-ca48-5f19f240e6b8"
      },
      "source": [
        "import os\n",
        "cur_path = \"/content/drive/MyDrive/graph-fraud-detection/\"\n",
        "os.chdir(cur_path)\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/graph-fraud-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aprSAaVaHiEX",
        "outputId": "6f03e207-cb92-492f-f37c-a664ae2bdd01"
      },
      "source": [
        "#!pip install dgl # This might install a version compatible with the current PyTorch\n",
        "#!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/repo.html\n",
        "!pip install dgl==1.1.2  # Or other version that works without GraphBolt\n",
        "\n",
        "#-cu101"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl==1.1.2 in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (1.15.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgVPj47IMMG4"
      },
      "source": [
        "## Training (All in 1)\n",
        "\n",
        "In this part, you can use this all-in-one method to train the model easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0mfuNcvBy6n",
        "outputId": "1f2f2ab7-fad0-4317-dfea-8ba4a10bd4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python train.py --n-epochs 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DLG version: 1.1.2\n",
            "numpy version:2.0.2 PyTorch version:2.6.0+cu124 DGL version:1.1.2\n",
            "Namespace(training_dir='./data', predicting_dir='./tdata', model_dir='./model/2025_07_20_08_28_15', output_dir='./output', nodes='features.csv', target_ntype='TransactionID', edges='relation*', labels='tags.csv', new_accounts='test.csv', compute_metrics=True, threshold=0, num_gpus=0, optimizer='adam', lr=0.01, n_epochs=10, n_hidden=16, n_layers=3, weight_decay=0.0005, dropout=0.2, embedding_size=360)\n",
            "Getting relation graphs from the following edge lists : ['relation_addr2_edgelist.csv', 'relation_P_emaildomain_edgelist.csv', 'relation_id_02_edgelist.csv', 'relation_id_17_edgelist.csv', 'relation_id_29_edgelist.csv', 'relation_id_14_edgelist.csv', 'relation_id_11_edgelist.csv', 'relation_id_30_edgelist.csv', 'relation_id_32_edgelist.csv', 'relation_id_13_edgelist.csv', 'relation_TransactionID_edgelist.csv', 'relation_id_12_edgelist.csv', 'relation_id_16_edgelist.csv', 'relation_id_27_edgelist.csv', 'relation_id_31_edgelist.csv', 'relation_id_28_edgelist.csv', 'relation_id_01_edgelist.csv', 'relation_id_15_edgelist.csv', 'relation_R_emaildomain_edgelist.csv', 'relation_card2_edgelist.csv', 'relation_id_06_edgelist.csv', 'relation_id_07_edgelist.csv', 'relation_id_05_edgelist.csv', 'relation_id_24_edgelist.csv', 'relation_id_04_edgelist.csv', 'relation_id_09_edgelist.csv', 'relation_id_08_edgelist.csv', 'relation_id_34_edgelist.csv', 'relation_DeviceType_edgelist.csv', 'relation_id_38_edgelist.csv', 'relation_id_22_edgelist.csv', 'relation_id_26_edgelist.csv', 'relation_id_35_edgelist.csv', 'relation_id_10_edgelist.csv', 'relation_DeviceInfo_edgelist.csv', 'relation_id_36_edgelist.csv', 'relation_id_18_edgelist.csv', 'relation_card3_edgelist.csv', 'relation_card1_edgelist.csv', 'relation_id_37_edgelist.csv', 'relation_id_23_edgelist.csv', 'relation_card4_edgelist.csv', 'relation_ProductCD_edgelist.csv', 'relation_id_03_edgelist.csv', 'relation_id_19_edgelist.csv', 'relation_id_21_edgelist.csv', 'relation_id_25_edgelist.csv', 'relation_addr1_edgelist.csv', 'relation_card5_edgelist.csv', 'relation_id_33_edgelist.csv', 'relation_id_20_edgelist.csv', 'relation_card6_edgelist.csv'] \n",
            "Read edges for target<addr2> from edgelist: ./data/relation_addr2_edgelist.csv\n",
            "Read edges for target<P_emaildomain> from edgelist: ./data/relation_P_emaildomain_edgelist.csv\n",
            "Read edges for target<id_02> from edgelist: ./data/relation_id_02_edgelist.csv\n",
            "Read edges for target<id_17> from edgelist: ./data/relation_id_17_edgelist.csv\n",
            "Read edges for target<id_29> from edgelist: ./data/relation_id_29_edgelist.csv\n",
            "Read edges for target<id_14> from edgelist: ./data/relation_id_14_edgelist.csv\n",
            "Read edges for target<id_11> from edgelist: ./data/relation_id_11_edgelist.csv\n",
            "Read edges for target<id_30> from edgelist: ./data/relation_id_30_edgelist.csv\n",
            "Read edges for target<id_32> from edgelist: ./data/relation_id_32_edgelist.csv\n",
            "Read edges for target<id_13> from edgelist: ./data/relation_id_13_edgelist.csv\n",
            "Will add self loop for target later......\n",
            "Read edges for target<id_12> from edgelist: ./data/relation_id_12_edgelist.csv\n",
            "Read edges for target<id_16> from edgelist: ./data/relation_id_16_edgelist.csv\n",
            "Read edges for target<id_27> from edgelist: ./data/relation_id_27_edgelist.csv\n",
            "Read edges for target<id_31> from edgelist: ./data/relation_id_31_edgelist.csv\n",
            "Read edges for target<id_28> from edgelist: ./data/relation_id_28_edgelist.csv\n",
            "Read edges for target<id_01> from edgelist: ./data/relation_id_01_edgelist.csv\n",
            "Read edges for target<id_15> from edgelist: ./data/relation_id_15_edgelist.csv\n",
            "Read edges for target<R_emaildomain> from edgelist: ./data/relation_R_emaildomain_edgelist.csv\n",
            "Read edges for target<card2> from edgelist: ./data/relation_card2_edgelist.csv\n",
            "Read edges for target<id_06> from edgelist: ./data/relation_id_06_edgelist.csv\n",
            "Read edges for target<id_07> from edgelist: ./data/relation_id_07_edgelist.csv\n",
            "Read edges for target<id_05> from edgelist: ./data/relation_id_05_edgelist.csv\n",
            "Read edges for target<id_24> from edgelist: ./data/relation_id_24_edgelist.csv\n",
            "Read edges for target<id_04> from edgelist: ./data/relation_id_04_edgelist.csv\n",
            "Read edges for target<id_09> from edgelist: ./data/relation_id_09_edgelist.csv\n",
            "Read edges for target<id_08> from edgelist: ./data/relation_id_08_edgelist.csv\n",
            "Read edges for target<id_34> from edgelist: ./data/relation_id_34_edgelist.csv\n",
            "Read edges for target<DeviceType> from edgelist: ./data/relation_DeviceType_edgelist.csv\n",
            "Read edges for target<id_38> from edgelist: ./data/relation_id_38_edgelist.csv\n",
            "Read edges for target<id_22> from edgelist: ./data/relation_id_22_edgelist.csv\n",
            "Read edges for target<id_26> from edgelist: ./data/relation_id_26_edgelist.csv\n",
            "Read edges for target<id_35> from edgelist: ./data/relation_id_35_edgelist.csv\n",
            "Read edges for target<id_10> from edgelist: ./data/relation_id_10_edgelist.csv\n",
            "Read edges for target<DeviceInfo> from edgelist: ./data/relation_DeviceInfo_edgelist.csv\n",
            "Read edges for target<id_36> from edgelist: ./data/relation_id_36_edgelist.csv\n",
            "Read edges for target<id_18> from edgelist: ./data/relation_id_18_edgelist.csv\n",
            "Read edges for target<card3> from edgelist: ./data/relation_card3_edgelist.csv\n",
            "Read edges for target<card1> from edgelist: ./data/relation_card1_edgelist.csv\n",
            "Read edges for target<id_37> from edgelist: ./data/relation_id_37_edgelist.csv\n",
            "Read edges for target<id_23> from edgelist: ./data/relation_id_23_edgelist.csv\n",
            "Read edges for target<card4> from edgelist: ./data/relation_card4_edgelist.csv\n",
            "Read edges for target<ProductCD> from edgelist: ./data/relation_ProductCD_edgelist.csv\n",
            "Read edges for target<id_03> from edgelist: ./data/relation_id_03_edgelist.csv\n",
            "Read edges for target<id_19> from edgelist: ./data/relation_id_19_edgelist.csv\n",
            "Read edges for target<id_21> from edgelist: ./data/relation_id_21_edgelist.csv\n",
            "Read edges for target<id_25> from edgelist: ./data/relation_id_25_edgelist.csv\n",
            "Read edges for target<addr1> from edgelist: ./data/relation_addr1_edgelist.csv\n",
            "Read edges for target<card5> from edgelist: ./data/relation_card5_edgelist.csv\n",
            "Read edges for target<id_33> from edgelist: ./data/relation_id_33_edgelist.csv\n",
            "Read edges for target<id_20> from edgelist: ./data/relation_id_20_edgelist.csv\n",
            "Read edges for target<card6> from edgelist: ./data/relation_card6_edgelist.csv\n",
            "Read in features for target nodes\n",
            "Constructed heterograph with the following metagraph structure: Node types ['DeviceInfo', 'DeviceType', 'P_emaildomain', 'ProductCD', 'R_emaildomain', 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'target'], Edge types[('DeviceInfo', 'DeviceInfo<>target', 'target'), ('DeviceType', 'DeviceType<>target', 'target'), ('P_emaildomain', 'P_emaildomain<>target', 'target'), ('ProductCD', 'ProductCD<>target', 'target'), ('R_emaildomain', 'R_emaildomain<>target', 'target'), ('addr1', 'addr1<>target', 'target'), ('addr2', 'addr2<>target', 'target'), ('card1', 'card1<>target', 'target'), ('card2', 'card2<>target', 'target'), ('card3', 'card3<>target', 'target'), ('card4', 'card4<>target', 'target'), ('card5', 'card5<>target', 'target'), ('card6', 'card6<>target', 'target'), ('id_01', 'id_01<>target', 'target'), ('id_02', 'id_02<>target', 'target'), ('id_03', 'id_03<>target', 'target'), ('id_04', 'id_04<>target', 'target'), ('id_05', 'id_05<>target', 'target'), ('id_06', 'id_06<>target', 'target'), ('id_07', 'id_07<>target', 'target'), ('id_08', 'id_08<>target', 'target'), ('id_09', 'id_09<>target', 'target'), ('id_10', 'id_10<>target', 'target'), ('id_11', 'id_11<>target', 'target'), ('id_12', 'id_12<>target', 'target'), ('id_13', 'id_13<>target', 'target'), ('id_14', 'id_14<>target', 'target'), ('id_15', 'id_15<>target', 'target'), ('id_16', 'id_16<>target', 'target'), ('id_17', 'id_17<>target', 'target'), ('id_18', 'id_18<>target', 'target'), ('id_19', 'id_19<>target', 'target'), ('id_20', 'id_20<>target', 'target'), ('id_21', 'id_21<>target', 'target'), ('id_22', 'id_22<>target', 'target'), ('id_23', 'id_23<>target', 'target'), ('id_24', 'id_24<>target', 'target'), ('id_25', 'id_25<>target', 'target'), ('id_26', 'id_26<>target', 'target'), ('id_27', 'id_27<>target', 'target'), ('id_28', 'id_28<>target', 'target'), ('id_29', 'id_29<>target', 'target'), ('id_30', 'id_30<>target', 'target'), ('id_31', 'id_31<>target', 'target'), ('id_32', 'id_32<>target', 'target'), ('id_33', 'id_33<>target', 'target'), ('id_34', 'id_34<>target', 'target'), ('id_35', 'id_35<>target', 'target'), ('id_36', 'id_36<>target', 'target'), ('id_37', 'id_37<>target', 'target'), ('id_38', 'id_38<>target', 'target'), ('target', 'self_relation', 'target'), ('target', 'target<>DeviceInfo', 'DeviceInfo'), ('target', 'target<>DeviceType', 'DeviceType'), ('target', 'target<>P_emaildomain', 'P_emaildomain'), ('target', 'target<>ProductCD', 'ProductCD'), ('target', 'target<>R_emaildomain', 'R_emaildomain'), ('target', 'target<>addr1', 'addr1'), ('target', 'target<>addr2', 'addr2'), ('target', 'target<>card1', 'card1'), ('target', 'target<>card2', 'card2'), ('target', 'target<>card3', 'card3'), ('target', 'target<>card4', 'card4'), ('target', 'target<>card5', 'card5'), ('target', 'target<>card6', 'card6'), ('target', 'target<>id_01', 'id_01'), ('target', 'target<>id_02', 'id_02'), ('target', 'target<>id_03', 'id_03'), ('target', 'target<>id_04', 'id_04'), ('target', 'target<>id_05', 'id_05'), ('target', 'target<>id_06', 'id_06'), ('target', 'target<>id_07', 'id_07'), ('target', 'target<>id_08', 'id_08'), ('target', 'target<>id_09', 'id_09'), ('target', 'target<>id_10', 'id_10'), ('target', 'target<>id_11', 'id_11'), ('target', 'target<>id_12', 'id_12'), ('target', 'target<>id_13', 'id_13'), ('target', 'target<>id_14', 'id_14'), ('target', 'target<>id_15', 'id_15'), ('target', 'target<>id_16', 'id_16'), ('target', 'target<>id_17', 'id_17'), ('target', 'target<>id_18', 'id_18'), ('target', 'target<>id_19', 'id_19'), ('target', 'target<>id_20', 'id_20'), ('target', 'target<>id_21', 'id_21'), ('target', 'target<>id_22', 'id_22'), ('target', 'target<>id_23', 'id_23'), ('target', 'target<>id_24', 'id_24'), ('target', 'target<>id_25', 'id_25'), ('target', 'target<>id_26', 'id_26'), ('target', 'target<>id_27', 'id_27'), ('target', 'target<>id_28', 'id_28'), ('target', 'target<>id_29', 'id_29'), ('target', 'target<>id_30', 'id_30'), ('target', 'target<>id_31', 'id_31'), ('target', 'target<>id_32', 'id_32'), ('target', 'target<>id_33', 'id_33'), ('target', 'target<>id_34', 'id_34'), ('target', 'target<>id_35', 'id_35'), ('target', 'target<>id_36', 'id_36'), ('target', 'target<>id_37', 'id_37'), ('target', 'target<>id_38', 'id_38')]\n",
            "Number of nodes of type target : 59054\n",
            "feature mean shape:torch.Size([390]), std shape:torch.Size([390])\n",
            "Getting labels\n",
            "Got labels\n",
            "----Data statistics------'\n",
            "                #Nodes: 82464\n",
            "                #Edges: 1943174\n",
            "                #Features Shape: torch.Size([59054, 390])\n",
            "                #Labeled Test samples: 11811.0\n",
            "Initializing Model\n",
            "Initialized Model\n",
            "Starting Model training\n",
            "Epoch 00000, Time(s) 5.2947, Loss 0.5307, F1 0.0000 \n",
            "Epoch 00001, Time(s) 5.0647, Loss 0.8945, F1 0.0000 \n",
            "Epoch 00002, Time(s) 4.7961, Loss 0.3730, F1 0.1890 \n",
            "Epoch 00003, Time(s) 4.7090, Loss 0.3560, F1 0.0095 \n",
            "Epoch 00004, Time(s) 4.7697, Loss 0.2124, F1 0.0029 \n",
            "Epoch 00005, Time(s) 4.7401, Loss 0.2404, F1 0.0057 \n",
            "Epoch 00006, Time(s) 4.6117, Loss 0.2288, F1 0.0124 \n",
            "Epoch 00007, Time(s) 4.6649, Loss 0.1994, F1 0.0365 \n",
            "Epoch 00008, Time(s) 4.5872, Loss 0.1606, F1 0.1155 \n",
            "Epoch 00009, Time(s) 4.6282, Loss 0.1353, F1 0.2594 \n",
            "Metrics\n",
            "Confusion Matrix:\n",
            "                                                    labels positive  labels negative\n",
            "predicted positive              113              327\n",
            "predicted negative              331            11040\n",
            "                                f1: 0.2557, precision: 0.2568, recall: 0.2545, acc: 0.9443, roc: 0.7703, pr: 0.2236, ap: 0.2243\n",
            "                             \n",
            "Finished Model training\n",
            "Saving model\n",
            "Model and metadata saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End here ..."
      ],
      "metadata": {
        "id": "LV_ZfjLsgVqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1/0 #for break the code."
      ],
      "metadata": {
        "id": "2duCgdpLU_mb",
        "outputId": "742f3dce-1d4f-4247-c787-e8cb095bc8ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-2354412189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSmqRg1eo8cT"
      },
      "source": [
        "## Training (Detailed)\n",
        "\n",
        "Besides the approach mentioned before, you can also use this detailed approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZWNPZTPOJSb"
      },
      "source": [
        "### Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6TREv-bfXKZ"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "\n",
        "import torch as th\n",
        "import dgl\n",
        "import numpy as np\n",
        "\n",
        "from gnn.estimator_fns import *\n",
        "from gnn.graph_utils import *\n",
        "from gnn.data import *\n",
        "from gnn.utils import *\n",
        "from gnn.pytorch_model import *\n",
        "from train import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9CmUjgaHXdj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E881gvwobfSz"
      },
      "source": [
        "### Load data\n",
        "\n",
        "Recall the edges we defined before and the csv files we used to save them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmqGrWm-HXdk"
      },
      "source": [
        "file_list = glob.glob('./data/*edgelist.csv')\n",
        "\n",
        "edges = \",\".join(map(lambda x: x.split(\"/\")[-1], [file for file in file_list if \"relation\" in file]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE2--V7AbfS0"
      },
      "source": [
        "To train the graph neural network, we need to define a few hyperparameters that determine properties such as the class of graph neural network models we will be using, the network architecture and the optimizer and optimization parameters.\n",
        "\n",
        "Here we're setting only a few of the hyperparameters, to see all the hyperparameters and their default values, see `gnn/estimator_fns.py`. The parameters set below are:\n",
        "\n",
        "- **nodes** is the name of the file that contains the node_ids of the target nodes and the node features.\n",
        "- **edges** is a regular expression that when expanded lists all the filenames for the edgelists\n",
        "- **labels** is the name of the file tha contains the target node_ids and their labels\n",
        "- **model** specify which graph neural network to use, this should be set to r-gcn\n",
        "\n",
        "The following hyperparameters can be tuned and adjusted to improve model performance\n",
        "\n",
        "- **batch-size** is the number nodes that are used to compute a single forward pass of the GNN\n",
        "- **embedding-size** is the size of the embedding dimension for non target nodes\n",
        "- **n-neighbors** is the number of neighbours to sample for each target node during graph sampling for mini-batch training\n",
        "- **n-layers** is the number of GNN layers in the model\n",
        "- **n-epochs** is the number of training epochs for the model training job\n",
        "- **optimizer** is the optimization algorithm used for gradient based parameter updates\n",
        "- **lr** is the learning rate for parameter updates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDQKAwpYo8cW"
      },
      "source": [
        "### Generate graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23aFsML_bfS1"
      },
      "source": [
        "print('numpy version:{} PyTorch version:{} DGL version:{}'.format(np.__version__,\n",
        "                                                                    th.__version__,\n",
        "                                                                    dgl.__version__))\n",
        "\n",
        "args = parse_args()\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4PfzLQKbfS1"
      },
      "source": [
        "args.edges = edges\n",
        "\n",
        "args.edges = get_edgelists('relation*', args.training_dir)\n",
        "\n",
        "g, features, target_id_to_node, id_to_node = construct_graph(args.training_dir,\n",
        "                                                                args.edges,\n",
        "                                                                args.nodes,\n",
        "                                                                args.target_ntype)\n",
        "\n",
        "mean, stdev, features = normalize(th.from_numpy(features))\n",
        "\n",
        "print('feature mean shape:{}, std shape:{}'.format(mean.shape, stdev.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bw1ceNebfS2"
      },
      "source": [
        "g.nodes['target'].data['features'] = features\n",
        "\n",
        "print(\"Getting labels\")\n",
        "n_nodes = g.number_of_nodes('target')\n",
        "\n",
        "labels, _, test_mask = get_labels(target_id_to_node,\n",
        "                                            n_nodes,\n",
        "                                            args.target_ntype,\n",
        "                                            os.path.join(args.training_dir, args.labels),\n",
        "                                            os.path.join(args.training_dir, args.new_accounts))\n",
        "print(\"Got labels\")\n",
        "\n",
        "labels = th.from_numpy(labels).float()\n",
        "test_mask = th.from_numpy(test_mask).float()\n",
        "\n",
        "n_nodes = th.sum(th.tensor([g.number_of_nodes(n_type) for n_type in g.ntypes]))\n",
        "n_edges = th.sum(th.tensor([g.number_of_edges(e_type) for e_type in g.etypes]))\n",
        "\n",
        "print(\"\"\"----Data statistics------'\n",
        "            #Nodes: {}\n",
        "            #Edges: {}\n",
        "            #Features Shape: {}\n",
        "            #Labeled Test samples: {}\"\"\".format(n_nodes,\n",
        "                                                    n_edges,\n",
        "                                                    features.shape,\n",
        "                                                    test_mask.sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjhjypJEo8cX"
      },
      "source": [
        "### Start training\n",
        "\n",
        "The training process and result will be saved in the same folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UETWzSN6bfS3"
      },
      "source": [
        "if args.num_gpus:\n",
        "    cuda = True\n",
        "    device = th.device('cuda:0')\n",
        "else:\n",
        "    cuda = False\n",
        "    device = th.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWQp2MxLHXdo"
      },
      "source": [
        "print(\"Initializing Model\")\n",
        "in_feats = features.shape[1]\n",
        "n_classes = 2\n",
        "\n",
        "ntype_dict = {n_type: g.number_of_nodes(n_type) for n_type in g.ntypes}\n",
        "\n",
        "model = get_model(ntype_dict, g.etypes, vars(args), in_feats, n_classes, device)\n",
        "print(\"Initialized Model\")\n",
        "\n",
        "features = features.to(device)\n",
        "\n",
        "labels = labels.long().to(device)\n",
        "test_mask = test_mask.to(device)\n",
        "# g = g.to(device)\n",
        "\n",
        "loss = th.nn.CrossEntropyLoss()\n",
        "\n",
        "# print(model)\n",
        "optim = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "print(\"Starting Model training\")\n",
        "\n",
        "initial_record()\n",
        "\n",
        "model, class_preds, pred_proba = train_fg(model, optim, loss, features, labels, g, g,\n",
        "                                            test_mask, device, args.n_epochs,\n",
        "                                            args.threshold,  args.compute_metrics)\n",
        "print(\"Finished Model training\")\n",
        "\n",
        "print(\"Saving model\")\n",
        "\n",
        "if not os.path.exists(args.model_dir):\n",
        "    os.makedirs(args.model_dir)\n",
        "\n",
        "save_model(g, model, args.model_dir, id_to_node, mean, stdev)\n",
        "print(\"Model and metadata saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u3-n_xdoZLc"
      },
      "source": [
        "%tb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2be32852"
      },
      "source": [
        "!pip install torchdata"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}